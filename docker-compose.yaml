# Use --compatibility flag with "docker-compose up" for deploy key translation

services:

  cardano-relay1:
    container_name: cardano-relay1
    environment:
      NODE_RTS: '-maxN4'
    image: cardano_node:latest
    #command: ["/bin/bash", "-c", "start-relay.sh"]           # Comment for node producer or relay with topology updater
    command: ["/bin/bash", "-c", "tail","-f","/dev/null"]   # Used for maintenance purpose
    tty: true
    volumes:
      - type: bind
        source: ./relay1/socket
        target: /cardano/socket
      - type: bind
        source: ./relay1/db
        target: /cardano/db
      - type: bind
        source: ./relay1/config
        target: /cardano/config
    ports:
      - "3001:3000"
    networks:
      cardano:
        aliases:
          - relay1
    restart: unless-stopped
    stop_signal: SIGINT
    stop_grace_period: 10s
    healthcheck:
      # Ping the node port to see if it responds.
      test: [ "CMD-SHELL", "cardano-cli ping -h localhost -p 3000 -t || exit 1" ]
      interval: 2m
      timeout: 10s
      retries: 5
      start_period: 4h # Allow enough time for validation & replay
    labels:
      autoheal: true
    logging:
      driver: "json-file"
      options:
        max-size: "200k"
        max-file: "10"

  cardano-relay2:
    container_name: cardano-relay2
    environment:
      NODE_RTS: '-maxN4'
    image: cardano_node:latest
    #command: ["/bin/bash", "-c", "start-relay.sh"]           # Comment for node producer or relay with topology updater
    command: ["/bin/bash", "-c", "tail","-f","/dev/null"]   # Used for maintenance purpose
    tty: true
    volumes:
      - type: bind
        source: ./relay2/socket
        target: /cardano/socket
      - type: bind
        source: ./relay2/db
        target: /cardano/db
      - type: bind
        source: ./relay2/config
        target: /cardano/config
    ports:
      - "3002:3000"
    networks:
      cardano:
        aliases:
          - relay2
    restart: unless-stopped
    stop_signal: SIGINT
    stop_grace_period: 10s
    healthcheck:
      # Ping the node port to see if it responds.
      test: [ "CMD-SHELL", "cardano-cli ping -h localhost -p 3000 -t || exit 1" ]
      interval: 2m
      timeout: 10s
      retries: 5
      start_period: 4h # Allow enough time for validation & replay
    labels:
      autoheal: true
    logging:
      driver: "json-file"
      options:
        max-size: "200k"
        max-file: "10"

  cardano-bp:
    container_name: cardano-bp
    environment:
      NODE_RTS: '-N6'
    image: cardano_node:latest
    #command: ["/bin/bash", "-c", "start-relay.sh"]           # Comment for node producer or relay with topology updater
    #command: ["/bin/bash", "-c", "start-producer.sh"]       # Uncomment for node producer
    command: ["/bin/bash", "-c", "tail","-f","/dev/null"]   # Used for maintenance purpose
    tty: true
    volumes:
      - type: bind
        source: ./bp/socket
        target: /cardano/socket
      - type: bind
        source: ./bp/db
        target: /cardano/db
      - type: bind
        source: ./bp/config
        target: /cardano/config
    ports:
      - "5000:3000"
    networks:
      cardano:
        aliases:
          - bp
    restart: unless-stopped
    stop_signal: SIGINT
    stop_grace_period: 10s
    healthcheck:
      # Ping the node port to see if it responds.
      test: [ "CMD-SHELL", "cardano-cli ping -h localhost -p 3000 -t || exit 1" ]
      interval: 2m
      timeout: 10s
      retries: 5
      start_period: 4h # Allow enough time for validation & replay
    labels:
      autoheal: true
    logging:
      driver: "json-file"
      options:
        max-size: "200k"
        max-file: "10"

  cardano-monitor:
    container_name: cardano-monitor
    image: cardano_monitor:latest
    command: ["start-monitoring.sh"]
    volumes:
      - type: volume
        source: prometheus-db
        target: /cardano/data
      - type: bind
        source: ./monitor/config
        target: /cardano/config
    ports:
      - "3200:3200"
    networks:
      cardano:
    restart: unless-stopped
    stop_grace_period: 5s
    logging:
      driver: "json-file"
      options:
        max-size: "200k"
        max-file: "10"

  cardano-submit:
    container_name: cardano-submit
    image: cardano_submit:latest
    command: ["/bin/bash", "-c", "start.sh"]
    depends_on:
      # Depend on both services to be healthy before starting.
      cardano-relay1:
        condition: service_healthy
    tty: true
    volumes:
      - type: bind
        source: ./relay1/socket
        target: /cardano/socket
      - type: bind
        source: ./relay1/config
        target: /cardano/config
        read_only: true
    ports:
      - "3080:3000"
    restart: unless-stopped
    stop_signal: SIGINT
    logging:
      driver: "json-file"
      options:
        max-size: "200k"
        max-file: "10"

  cardano-db-sync:
    container_name: db-sync
    image: cardano_db_sync:13.1.0.2
    environment:
      PGPASSFILE: '/cardano/config/pgpass-mainnet'
    #command: ["/bin/bash", "-c", "start.sh"]
    command: ["/bin/bash", "-c", "sleep.sh"]   # Used for maintenance purpose
    depends_on:
      # Depend on both services to be healthy before starting.
      cardano-relay1:
        condition: service_healthy
      cardano-postgres:
        condition: service_healthy
    volumes:
      - type: bind
        source: ./db-sync/config
        target: /cardano/config
        read_only: true
      - type: bind
        source: ./db-sync/snapshot
        target: /cardano/snapshot
      - type: bind
        source: ./relay1/socket
        target: /cardano/socket
      - type: volume
        source: db-sync-ledger
        target: /cardano/ledger-state
    networks:
      db-sync:
    restart: unless-stopped
    stop_grace_period: 20s
    logging:
      driver: "json-file"
      options:
        max-size: "200k"
        max-file: "10"

  cardano-postgres:
    container_name: cardano-postgres
    image: postgres:14.10-alpine
    environment:
      - POSTGRES_LOGGING=true
      - POSTGRES_DB_FILE=/run/secrets/postgres_db
      - POSTGRES_PASSWORD_FILE=/run/secrets/postgres_password
      - POSTGRES_USER_FILE=/run/secrets/postgres_user
    secrets:
      - postgres_password
      - postgres_user
      - postgres_db
    command: ${POSTGRES_ARGS:--c maintenance_work_mem=1GB -c max_parallel_maintenance_workers=4 -c max_wal_size=4GB -c checkpoint_timeout=15min -c checkpoint_completion_target=0.9}
    ports:
      - "5433:5432"
    networks:
      db-sync:
        aliases:
          - postgres
    volumes:
      - type: volume
        source: postgres
        target: /var/lib/postgresql/data
    restart: unless-stopped
    healthcheck:
      # Use pg_isready to check postgres is running. Substitute different
      # user `postgres` if you've setup differently to config/pgpass-mainnet
      test: ["CMD-SHELL", "pg_isready -U postgres"]
      interval: 10s
      timeout: 5s
      retries: 5
    labels:
      autoheal: true
    logging:
      driver: "json-file"
      options:
        max-size: "200k"
        max-file: "10"

  mithril:
    container_name: mithril
    image: mithril_signer:latest
    #command: ["/bin/bash", "-c", "start.sh"]
    command: ["/bin/bash", "-c", "tail","-f","/dev/null"]   # Used for maintenance purpose
    depends_on:
      # Depend on block producer service to be healthy before starting.
      cardano-bp:
        condition: service_healthy
    environment:
      DB_DIRECTORY: '/cardano/db'
      DATA_STORES_DIRECTORY: '/cardano/stores'
      CARDANO_CLI_PATH: '/cardano/bin/cardano-cli'
      OPERATIONAL_CERTIFICATE_PATH: '/cardano/config/node.cert'
      KES_SECRET_KEY_PATH: '/cardano/config/kes.skey'
      RUN_INTERVAL: 60000
      STORE_RETENTION_LIMIT: 5
      NETWORK: 'mainnet'
#      GENESIS_VERIFICATION_KEY: '5b3139312c36362c3134302c3138352c3133382c31312c3233372c3230372c3235302c3134342c32372c322c3138382c33302c31322c38312c3135352c3230342c31302c3137392c37352c32332c3133382c3139362c3231372c352c31342c32302c35372c37392c33392c3137365d'
      ERA_READER_ADAPTER_TYPE: 'cardano-chain'
      ERA_READER_ADAPTER_PARAMS: '{"address": "addr1qy72kwgm6kypyc5maw0h8mfagwag8wjnx6emgfnsnhqaml6gx7gg4tzplw9l32nsgclqax7stc4u6c5dn0ctljwscm2sqv0teg", "verification_key": "5b31312c3133342c3231352c37362c3134312c3232302c3131312c3135342c36332c3233302c3131342c31322c38372c37342c39342c3137322c3133322c32372c39362c3138362c3132362c3137382c31392c3131342c33302c3234332c36342c3134312c3131302c38332c38362c31395d"}'
      RELAY_ENDPOINT: 'SQUID_RELAY_HOST:3132'
      AGGREGATOR_ENDPOINT: 'https://aggregator.release-mainnet.api.mithril.network/aggregator'
    tty: true
    volumes:
      - type: bind
        source: ./bp/socket
        target: /cardano/socket
      - type: bind
        source: ./bp/db
        target: /cardano/db
        read_only: true
      - type: bind
        source: ./bp/config
        target: /cardano/config
        read_only: true
      - type: volume
        source: mithril-stores
        target: /cardano/stores
    ports:
      - "3132:3132"
    networks:
      cardano:
        aliases:
          - mithril
    restart: unless-stopped
    stop_signal: SIGINT
    stop_grace_period: 10s
    logging:
      driver: "json-file"
      options:
        max-size: "200k"
        max-file: "10"

  squid:
    container_name: squid
    image: squid:latest
    #command: ["/bin/bash", "-c", "start.sh"]
    command: ["/bin/bash", "-c", "tail","-f","/dev/null"]   # Used for maintenance purpose
    tty: true
    volumes:
      - type: bind
        source: ./squid
        target: /config
    ports:
      - "3132:3132"
    restart: unless-stopped
    stop_signal: SIGINT
    logging:
      driver: "json-file"
      options:
        max-size: "200k"
        max-file: "10"

  mithril-client:
    container_name: mithril-client
    image: mithril_client:latest
    environment:
      GENESIS_VERIFICATION_KEY: '5b3139312c36362c3134302c3138352c3133382c31312c3233372c3230372c3235302c3134342c32372c322c3138382c33302c31322c38312c3135352c3230342c31302c3137392c37352c32332c3133382c3139362c3231372c352c31342c32302c35372c37392c33392c3137365d'
      AGGREGATOR_ENDPOINT: 'https://aggregator.release-mainnet.api.mithril.network/aggregator'
    tty: true
    volumes:
      - type: bind
        source: ./mithril-client
        target: /cardano/db
    restart: unless-stopped
    stop_signal: SIGINT
    logging:
      driver: "json-file"
      options:
        max-size: "200k"
        max-file: "10"

  blockfrost:
    container_name: blockfrost
    image: blockfrost-platform:0.0.2
    entrypoint:
      - /app/blockfrost-platform
      - --network
      - mainnet
      - --secret
      - !!!SECRET!!!
      - --reward-address
      - !!!ADDRESS!!!
      - --server-port
      - "3000"
      - --node-socket-path
      - /ipc/node.sock
    depends_on:
      - relay2
    volumes:
      - type: bind
        source: ./relay2/socket
        target: /ipc
    profiles: [ "" ]
    ports:
      - "3000:3000"
    restart: on-failure
    healthcheck:
      # Ping the EKG port to see if it responds.
      # Assuming if EKG isn't up then the rest of cardano-node isn't either.
      # test: [ "CMD-SHELL", "curl -H \"Accept: application/json\" -f 127.0.0.1:3000 || exit 1" ]
      test: [ "CMD-SHELL", "curl -H \"Accept: application/json\" -f -s 127.0.0.1:3000 | jq -e \".healthy == true\" || exit 1" ]
      interval: 60s
      timeout: 10s
      retries: 5
    labels:
      autoheal: true
    logging:
      driver: "json-file"
      options:
        max-size: "200k"
        max-file: "10"

  autoheal:
    container_name: autoheal
    environment:
      AUTOHEAL_CONTAINER_LABEL: autoheal
      AUTOHEAL_ONLY_MONITOR_RUNNING: true
      AUTOHEAL_INTERVAL: 180
    image: willfarrell/autoheal:latest
    network_mode: none
    restart: always
    volumes:
      - /etc/localtime:/etc/localtime:ro
      - /var/run/docker.sock:/var/run/docker.sock

volumes:
  prometheus-db:
  postgres:
  db-sync-ledger:
  mithril-stores:

networks:
  cardano:
  db-sync:

secrets:
  postgres_db:
    file: ./secrets/postgres_db
  postgres_password:
    file: ./secrets/postgres_password
  postgres_user:
    file: ./secrets/postgres_user
